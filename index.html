
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta content="text/html; charset=UTF-8" name="Content-Type">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="keywords" content="Virtual Try-On, Human Modeling, Garment modeling, 3D Shape Modeling, 2D-3D Reconstruction">
    <meta name="description"
        content=" TBD ">
    <!-- Meta og tags -->
    <meta property="og:title" content="ScanNet++ Dataset">
    <meta property="og:type" content="website">
    <meta property="og:site_name" content="ScanNet++ Dataset">
    <meta property="og:description"
        content=" TBD ">
    <meta property="og:image"
        content="https://kaldir.vc.in.tum.de/scannetpp/static/images/spp-thumbnail.jpg">
    <meta property="og:url" content="https://kaldir.vc.in.tum.de/scannetpp/">
    
    <title>Visual Modeling Challenges for 2D-3D Virtual Try-On</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.3.0/font/bootstrap-icons.css">
    <!-- <link href="https://fonts.googleapis.com/css?family=Open+Sans|Google+Sans|Noto+Sans|Castoro:400,700" rel="stylesheet"> -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@700&family=Open+Sans:wght@400;700&display=swap"
        rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
    <link rel="stylesheet" href="/scannetpp/static/css/index.css">
    <link rel="stylesheet" href="/scannetpp/static/css/cvpr2025/index.css">
    <link rel="icon" href="/scannetpp/static/images/favicon.ico">
</head>

<body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark mb-2">
        <div class="container-xxl">
            <a class="navbar-brand" href="/scannetpp/">
                Visual Modeling Challenges for 2D-3D Virtual Try-On
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav my-1">
                    <li class="nav-item ">
                        <a href="#intro" class="nav-link">
                            Introduction
                        </a>
                    </li>
                    <li class="nav-item ">
                        <a href="#date" class="nav-link">
                            Important Dates
                        </a>
                    </li>
                    <li class="nav-item ">
                        <a href="#schedule" class="nav-link">
                            Schedule
                        </a>
                    </li>
                    <li class="nav-item">
                        <a href="#speakers" class="nav-link">
                            Invited Speakers
                        </a>
                    </li>
                    <li class="nav-item ">
                        <a href="#organizers" class="nav-link">
                            Organizers
                        </a>
                    </li>
                    <li class="nav-item ">
                        <a href="#Archive" class="nav-link">
                            Archive
                        </a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <p><br /></p>
    <div class="row">
	  <div class="col-xs-12">
	    <center><h1>Visual Modeling Challenges for 2D-3D Virtual Try-On</h1></center>
	    <center><h2>CVPR 2025 Workshop, Nashville TN</h2></center>
	    <center>Date to be decided</center>
	  </div>
	</div>
	<p><br /></p>


    <div class="container my-4">
        <div id="intro" class="row my-2">

		<div class="col-xs-12">
                      <img src="/scannetpp/static/images/cvpr2025/tasks.jpg" alt="teaser" class="img-fluid">
	</br></br>
                </div>


            <div class="col-xs-12 mb-1">
                <h2>Introduction</h2>
            </div>
            <div class="col-xs-12">

		    Everyone likes shopping; Online shopping, huge catalog, large diversity, novel products, all easily accessible; personalised experience if customers can try products while shopping online; increases customer purchase satisfaction, resulting in an increase in traffic and  low return rate

            <!-- in red -->
            <br>
            <br>
            <span style="color:rgb(216, 83, 0);"><b>ðŸ“¢ New this year ðŸ“¢</b></span> ScanNet++ v2 released with <b>1000+ scenes</b>, more scene types, improved annotations and poses. <a href="https://kaldir.vc.in.tum.de/scannetpp/changelog">Check it out!</a>

            </div>
        </div>

        <p><br /></p>

        <div id="schedule" class="row my-2">
            <div class="col-xs-12 mb-1">
		    <h2>Schedule</h2>
            </div>
            <div class="col-xs-12">
                <table class="table table-striped">
                    <tbody>
                        <tr>
                            <td>Welcome and Introduction</td>
                            <td>13:30 - 13:45</td>
                        </tr>
                        <tr>
                            <td>Invited Talk 1</td>
                            <td>13:45 - 14:20</td>
                        </tr>
                        <tr>
                            <td>Invited Talk 2</td>
                            <td>14:20 - 14:55</td>
                        </tr>
                        <tr>
                            <!-- <td style="white-space:pre-wrap; word-wrap:break-word">Winner Talks: <i>TBD</i> -->
                            <td>Winner Talks: <i>TBD</i>
				
			                </td>
                            <td>14:55 - 15:40</td>
                        <tr>
                            <td>Invited Talk 3</td>
                            <td>15:40 - 16:15</td>
                        </tr>
                        <tr>
                            <td>Invited Talk 4</td>
                            <td>16:15 - 16:50</td>
                        </tr>
                        <tr>
                            <td>Panel Discussion and Conclusion</td>
                            <td>16:50 - 17:30</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
        <p><br /></p>

        <div id="speakers" class="row mb-2">
            <div class="col-xs-12 mb-1">
                <h2>Invited Speakers</h2>
            </div>
        </div>

        <div class="row mb-1">
            <div class="col-md-12">
                <a href="https://cordeliaschmid.github.io/"><img class="people-pic"
                        style="float:left;margin-right:50px;"
                        src="/scannetpp/static/images/cvpr2025/people/cordelia.jpg" /></a>
                <p>
                    <b><a href="https://cordeliaschmid.github.io/">Cordelia Schmid</a></b> is a
                    research director at Inria. She holds a M.S. degree in
                    Computer Science from the University of Karlsruhe
                    and a Doctorate, also in Computer Science, from the
                    Institut National Polytechnique de Grenoble (INPG).
                    Her doctoral thesis on "Local Greyvalue Invariants for
                    Image Matching and Retrieval" received the best thesis
                    award from INPG in 1996. She received the Habilitation degree in 2001 for her thesis entitled "From Image Matching to Learning Visual Models". Dr. Schmid is
                    a member of the German National Academy of Sciences, Leopoldina and a fellow of IEEE and the ELLIS
                    society. She was awarded the Longuet-Higgins prize
                    in 2006, 2014 and 2016, the Koenderink prize in 2018
                    and the Helmholtz price in 2023, all for fundamental
                    contributions in computer vision that have withstood
                    the test of time. She received an ERC advanced grant
                    in 2013, the Humbolt research award in 2015, the Inria
                    & French Academy of Science Grand Prix in 2016, the
                    Royal Society Milner award in 2020 and the PAMI distinguished researcher award in 2021. In 2023 she received the Korber European Science Prize. Dr. Schmid 
                    has been an Associate Editor for IEEE PAMI (2001-
                    2005) and for IJCV (2004â€“2012), an editor-in-chief for
                    IJCV (2013â€“2018), a program chair of IEEE CVPR
                    2005 and ECCV 2012 as well as a general chair of
                    IEEE CVPR 2015, ECCV 2020 and ICCV 2023. Starting 2018 she holds a joint appointment with Google
                    research.
                </p>
            </div>
        </div>

        <div class="row mb-1">
            <div class="col-md-12">
                <a href="https://www.robots.ox.ac.uk/~vedaldi/"><img class="people-pic"
                        style="float:left;margin-right:50px;"
                        src="/scannetpp/static/images/cvpr2025/people/andrea.jpg" /></a>
                <p>
                    <b><a href="https://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a></b> is a Professor of Computer Vision and Machine Learning and
                    a co-lead of the VGG group at the Engineering Science
                    department of the University of Oxford. He researches
                    computer vision and machine learning methods to understand the content of images and videos automatically, with little to no manual supervision, in terms of
                    semantics and 3D geometry.
                </p>
            </div>
        </div>

        <div class="row mb-1">
            <div class="col-md-12">
                <a href="https://stanford.edu/~gordonwz/"><img class="people-pic"
                        style="float:left;margin-right:50px;"
                        src="/scannetpp/static/images/cvpr2025/people/gordon.jpg" /></a>
                <p>
                    <b><a href="https://stanford.edu/~gordonwz/">Gordon Wetzstein</a></b> is
                    an Associate Professor of Electrical Engineering and,
                    by courtesy, of Computer Science at Stanford University. He is the leader of the Stanford Computational
                    Imaging Lab and a faculty co-director of the Stanford Center for Image Systems Engineering. At the
                    intersection of computer graphics and vision, artificial
                    intelligence, computational optics, and applied vision
                    science, Prof. Wetzstein's research has a wide range
                    of applications in next-generation imaging, wearable
                    computing, and neural rendering systems. Prof. Wetzstein is a Fellow of Optica and the recipient of numerous awards, including an IEEE VGTC Virtual Reality Technical Achievement Award, an NSF CAREER
                    Award, an Alfred P. Sloan Fellowship, an ACM SIGGRAPH Significant New Researcher Award, a Presidential Early Career Award for Scientists and Engineers (PECASE), an SPIE Early Career Achievement
                    Award, an Electronic Imaging Scientist of the Year
                    Award, an Alain Fournier Ph.D. Dissertation Award as
                    well as many Best Paper and Demo Awards.
                </p>
            </div>
        </div>

        <div class="row mb-1">
            <div class="col-md-12">
                <a href="https://theialab.ca/"><img class="people-pic"
                        style="float:left;margin-right:50px;"
                        src="/scannetpp/static/images/cvpr2025/people/andrea_t.jpg" /></a>
                <p>
                    <b><a href="https://theialab.ca/">Andrea Tagliasacchi </a></b> is an associate professor at Simon Fraser University
                    (Vancouver, Canada) where he holds the appointment
                    of Visual Computing Research Chair within the school
                    of computing science. He is also a part-time (20%)
                    staff research scientist at Google DeepMind (Toronto,
                    Canada), as well as an associate professor (status only)
                    in the computer science department at the University of
                    Toronto. Before joining SFU, he spent four wonderful
                    years as a full-time researcher at Google (mentored by
                    Paul Lalonde, Geoffrey Hinton, and David Fleet). Before joining Google, he was an assistant professor at
                    the University of Victoria (2015-2017), where he held
                    the Industrial Research Chair in 3D Sensing (jointly
                    sponsored by Google and Intel). His alma mater include EPFL (postdoc) SFU (PhD, NSERC Alexander
                    Graham Bell fellow) and Politecnico di Milano (MSc,
                    gold medalist). Several of his papers have received
                    best-paper award nominations at top-tier graphics and
                    vision conferences, and he is the recipient of the 2015
                    SGP best paper award, the 2020 CVPR best student paper award, and the 2024 CVPR best paper award (honorable mention). His research focuses on 3D visual
                    perception, which lies at the intersection of computer
                    vision, computer graphics and machine learning.
                </p>
            </div>
        </div>

        <div class="row mb-1">
            <div class="col-md-12">
                <a href="http://people.eecs.berkeley.edu/~kanazawa/"><img class="people-pic"
                        style="float:left;margin-right:50px;"
                        src="/scannetpp/static/images/cvpr2025/people/angjoo.jpg" /></a>
                <p>
                    <b><a href="http://people.eecs.berkeley.edu/~kanazawa/">Angjoo Kanazawa</a></b> is
                    an Assistant Professor in the Department of Electrical
                    Engineering and Computer Sciences at the University
                    of California, Berkeley. She leads the Kanazawa AI
                    Research (KAIR) lab under BAIR. She also serves on
                    the advisory board of Wonder Dynamics. Previously,
                    Angjoo was a Research Scientist at Google Research,
                    and BAIR postdoc at UC Berkeley advised by Jitendra
                    Malik, Alexei A. Efros and Trevor Darrell. She completed her PhD in Computer Science at the University
                    of Maryland, College Park with her advisor David Jacobs.
                </p>
            </div>
        </div>

        <div id="organizers" class="row my-2">
            <div class="col-xs-12 mb-1">
                <h2>Organizers</h2>
            </div>
        </div>
        <div class="row mb-1">
            <div class="col-2">
                <a href="https://angeladai.github.io/">
                    <img class="people-pic"
                        src="/scannetpp/static/images/cvpr2025/people/angela.jpg" />
                </a>
                <div class="people-name">
                    <a href="https://angeladai.github.io/">Angela Dai</a>
                    <h6>Technical University of Munich</h6>
                </div>
            </div>

            <div class="col-2">
                <a href="https://liu115.github.io/">
			<img class="people-pic" src="/scannetpp/static/images/cvpr2025/people/yueh-cheng.jpg" />
                </a>
                <div class="people-name">
                    <a href="https://liu115.github.io/">Yueh-Cheng Liu</a>
                    <h6>Technical University of Munich</h6>
                </div>
            </div>

            <div class="col-2">
                <a href="https://cy94.github.io/">
			<img class="people-pic" src="/scannetpp/static/images/cvpr2025/people/chandan.jpg" />
                </a>
                <div class="people-name">
                    <a href="https://cy94.github.io/">Chandan Yeshwanth</a>
                    <h6>Technical University of Munich</h6>
                </div>
            </div>

	    <div class="col-2">
                <a href="https://bmild.github.io/">
			<img class="people-pic" src="/scannetpp/static/images/cvpr2025/people/ben.jpg" />
                </a>
                <div class="people-name">
                    <a href="https://bmild.github.io/">Ben Mildenhall</a>
		    <h6></h6>
                </div>
            </div>

	    <div class="col-2">
                <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">
			<img class="people-pic" src="/scannetpp/static/images/cvpr2025/people/peter.jpg" />
                </a>
                <div class="people-name">
                    <a href="https://scholar.google.com/citations?user=CxbDDRMAAAAJ&hl=en">Peter Kontschieder</a>
                    <h6>Meta</h6>
                </div>
            </div>

            <div class="col-2">
                <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">
			<img class="people-pic" src="/scannetpp/static/images/cvpr2025/people/matthias.jpg" />
                </a>
                <div class="people-name">
                    <a href="https://niessnerlab.org/members/matthias_niessner/profile.html">Matthias Niessner</a>
                    <h6>Technical University of Munich</h6>
                </div>
            </div>
        </div>

    </div>
</body>

</html>
